{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "We train an LSTM with gumbel-sigmoid gates on a toy language modelling problem.\n",
    "Such LSTM can than be binarized to reach signifficantly greater speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate mtg cards\n",
    "* Regular RNN language modelling done by LSTM with \"binary\" gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_token = \" \"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token+name for name in names]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n samples =  7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print 'n samples = ',len(names)\n",
    "for x in names[::1000]:\n",
    "    print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens =  55\n"
     ]
    }
   ],
   "source": [
    "#all unique characters go here\n",
    "token_set = set()\n",
    "for name in names:\n",
    "    for letter in name:\n",
    "        token_set.add(letter)\n",
    "\n",
    "tokens = list(token_set)\n",
    "\n",
    "print 'n_tokens = ',len(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!token_to_id = <dictionary of symbol -> its identifier (index in tokens list)>\n",
    "token_to_id = {t:i for i,t in enumerate(tokens) }\n",
    "\n",
    "#!id_to_token = < dictionary of symbol identifier -> symbol itself>\n",
    "id_to_token = {i:t for i,t in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEACAYAAAC08h1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl6TGGPyS1Jj/AyU4/MHunlgAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd95f5d7b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(map(len,names),bins=25);\n",
    "\n",
    "# truncate names longer than MAX_LEN characters. \n",
    "MAX_LEN = min([60,max(list(map(len,names)))])\n",
    "#ADJUST IF YOU ARE UP TO SOMETHING SERIOUS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names_ix = list(map(lambda name: list(map(token_to_id.get,name)),names))\n",
    "\n",
    "\n",
    "#crop long names and pad short ones\n",
    "for i in range(len(names_ix)):\n",
    "    names_ix[i] = names_ix[i][:MAX_LEN] #crop too long\n",
    "    \n",
    "    if len(names_ix[i]) < MAX_LEN:\n",
    "        names_ix[i] += [token_to_id[\" \"]]*(MAX_LEN - len(names_ix[i])) #pad too short\n",
    "        \n",
    "assert len(set(map(len,names_ix)))==1\n",
    "\n",
    "names_ix = np.array(names_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet import Recurrence\n",
    "from lasagne.layers import *\n",
    "from agentnet.memory import *\n",
    "from agentnet.resolver import ProbabilisticResolver\n",
    "from gumbel_sigmoid import GumbelSigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence = T.matrix('token sequence','int64')\n",
    "\n",
    "inputs = sequence[:,:-1]\n",
    "targets = sequence[:,1:]\n",
    "\n",
    "\n",
    "l_input_sequence = InputLayer(shape=(None, None),input_var=inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build NN\n",
    "\n",
    "You'll be building a model that takes token sequence and predicts next tokens at each tick\n",
    "\n",
    "This is basically equivalent to how rnn step was described in the lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###One step of rnn\n",
    "\n",
    "class rnn:\n",
    "    n_hid = 50\n",
    "    temp = theano.shared(np.float32(1.0))\n",
    "    \n",
    "    #inputs\n",
    "    inp = InputLayer((None,),name='current character')\n",
    "    prev_cell = InputLayer((None,n_hid),name='previous lstm cell')\n",
    "    prev_hid = InputLayer((None,n_hid),name='previous ltsm output')\n",
    "    \n",
    "    #recurrent part\n",
    "    emb = EmbeddingLayer(inp, len(tokens), 30,name='emb')\n",
    "    \n",
    "    new_cell,new_hid = LSTMCell(prev_cell,prev_hid,emb,\n",
    "                                inputgate_nonlinearity=GumbelSigmoid(temp),\n",
    "                                forgetgate_nonlinearity=GumbelSigmoid(temp),\n",
    "                                outputgate_nonlinearity=GumbelSigmoid(temp),\n",
    "                                name=\"rnn\") \n",
    "    \n",
    "    next_token_probas = DenseLayer(new_hid,len(tokens),nonlinearity=T.nnet.softmax)\n",
    "    \n",
    "    #pick next token from predicted probas\n",
    "    next_token = ProbabilisticResolver(next_token_probas)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss && Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/Downloads/AgentNet/agentnet/agent/recurrence.py:188: UserWarning: State_variables recommended type is OrderedDict.\n",
      "                Otherwise, order of agent state outputs from get_sessions and get_agent_reaction methods\n",
      "                may depend on python configuration.\n",
      "\n",
      "                Current order is: [<lasagne.layers.merge.ElemwiseMergeLayer object at 0x7fd955a0a790>, <lasagne.layers.merge.ElemwiseMergeLayer object at 0x7fd9555f27d0>]\n",
      "                You may find OrderedDict in standard collections module: from collections import OrderedDict\n",
      "                \n",
      "  \"\"\".format(state_variables=list(self.state_variables.keys())))\n",
      "/home/jheuristic/Downloads/AgentNet/agentnet/agent/recurrence.py:300: UserWarning: You are giving Recurrence an input sequence of undefined length (None).\n",
      "Make sure it is always above <unspecified>(n_steps) you specified for recurrence\n",
      "  \"Make sure it is always above {}(n_steps) you specified for recurrence\".format(n_steps or \"<unspecified>\"))\n"
     ]
    }
   ],
   "source": [
    "training_loop = Recurrence(\n",
    "    state_variables={rnn.new_hid:rnn.prev_hid,\n",
    "                     rnn.new_cell:rnn.prev_cell},\n",
    "    input_sequences={rnn.inp:l_input_sequence},\n",
    "    tracked_outputs=[rnn.next_token_probas,],\n",
    "    unroll_scan=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[emb.W, rnn.b_to_ingate, rnn.W_previous ltsm output_to_ingate, rnn.W_emb_to_ingate, rnn.b_to_forgetgate, rnn.W_previous ltsm output_to_forgetgate, rnn.W_emb_to_forgetgate, rnn.b_to_cell, rnn.W_previous ltsm output_to_cell, rnn.W_emb_to_cell, rnn.b_to_outgate, rnn.W_previous ltsm output_to_outgate, rnn.W_emb_to_outgate, rnn.W_cell_to_ingate_peephole.scales, rnn.W_cell_to_forgetgate_peephole.scales, rnn.W_cell_to_outgate_peephole.scales, W, b]\n"
     ]
    }
   ],
   "source": [
    "# Model weights\n",
    "weights = lasagne.layers.get_all_params(training_loop,trainable=True)\n",
    "print weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_probabilities = lasagne.layers.get_output(training_loop[rnn.next_token_probas])\n",
    "#If you use dropout do not forget to create deterministic version for evaluation\n",
    "\n",
    "loss = lasagne.objectives.categorical_crossentropy(predicted_probabilities.reshape((-1,len(tokens))),\n",
    "                                                   targets.reshape((-1,))).mean()\n",
    "#<Loss function - a simple categorical crossentropy will do, maybe add some regularizer>\n",
    "\n",
    "updates = lasagne.updates.adam(loss,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training\n",
    "train_step = theano.function([sequence], loss,\n",
    "                             updates=training_loop.get_automatic_updates()+updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generation\n",
    "\n",
    "here we re-wire the recurrent network so that it's output is fed back to it's input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/Downloads/AgentNet/agentnet/agent/recurrence.py:188: UserWarning: State_variables recommended type is OrderedDict.\n",
      "                Otherwise, order of agent state outputs from get_sessions and get_agent_reaction methods\n",
      "                may depend on python configuration.\n",
      "\n",
      "                Current order is: [<lasagne.layers.merge.ElemwiseMergeLayer object at 0x7fd955a0a790>, <lasagne.layers.input.InputLayer object at 0x7fd95539fd50>, <agentnet.resolver.probabilistic.ProbabilisticResolver object at 0x7fd9555f2910>]\n",
      "                You may find OrderedDict in standard collections module: from collections import OrderedDict\n",
      "                \n",
      "  \"\"\".format(state_variables=list(self.state_variables.keys())))\n"
     ]
    }
   ],
   "source": [
    "n_steps = T.scalar(dtype='int32')\n",
    "feedback_loop = Recurrence(\n",
    "    state_variables={rnn.prev_cell:rnn.prev_cell,\n",
    "                     rnn.new_hid:rnn.prev_hid,\n",
    "                     rnn.next_token:rnn.inp},\n",
    "    tracked_outputs=[rnn.next_token_probas,],\n",
    "    batch_size=1,\n",
    "    n_steps=n_steps,\n",
    "    unroll_scan=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generated_tokens = get_output(feedback_loop[rnn.next_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generate_sample = theano.function([n_steps],generated_tokens,updates=feedback_loop.get_automatic_updates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_string(length=MAX_LEN):\n",
    "    output_indices = generate_sample(length)[0]\n",
    "    \n",
    "    return ''.join(tokens[i] for i in output_indices)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lE rNJbmxTEkSaAo'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "Here you can tweak parameters or insert your generation function\n",
    "\n",
    "\n",
    "__Once something word-like starts generating, try increasing seq_length__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_batch(data, batch_size):\n",
    "    \n",
    "    rows = data[np.random.randint(0,len(data),size=batch_size)]\n",
    "    \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_step' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-9dc5d9ee6009>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mavg_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_ix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\nEpoch {} average loss = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_cost\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatches_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_step' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training ...\")\n",
    "\n",
    "\n",
    "#total N iterations\n",
    "n_epochs=100\n",
    "\n",
    "# how many minibatches are there in the epoch \n",
    "batches_per_epoch = 500\n",
    "\n",
    "#how many training sequences are processed in a single function call\n",
    "batch_size=10\n",
    "\n",
    "\n",
    "for epoch in xrange(n_epochs):\n",
    "\n",
    "    avg_cost = 0;\n",
    "    for _ in range(batches_per_epoch):\n",
    "        \n",
    "        avg_cost += train_step(sample_batch(names_ix,batch_size))\n",
    "        \n",
    "    print(\"\\n\\nEpoch {} average loss = {}\".format(epoch, avg_cost / batches_per_epoch))\n",
    "\n",
    "    print \"Generated names\"\n",
    "    for i in range(10):\n",
    "        print generate_string(),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And now,\n",
    "* try lstm/gru\n",
    "* try several layers\n",
    "* try mtg cards\n",
    "* try your own dataset of any kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
